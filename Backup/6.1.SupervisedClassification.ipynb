{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manipulation des données\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# matplotlib et seaborn pour les représentations graphiques\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "\n",
    "# sklearn preprocessing pour le traiter les variables catégorielles\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Gestion du système de fichiers\n",
    "import os\n",
    "from os import listdir\n",
    "\n",
    "# Suppression des alertes\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5eec66ec172ce096cd4e5c947686b56a.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ffc2e1fc7c886ec09a331040ada038aa.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AI6c3768639e82ceaeab681e083b897672.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AId98fac46793639eceaaa2e74cadd4973.jpg</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6e812fbc03331ab363789b0f2d6b3ff2.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2095</th>\n",
       "      <td>AIa3dea07b2f7bf48276d32513091be717.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2096</th>\n",
       "      <td>AId47f1cb78db4a23e2516e2d34da34c8a.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097</th>\n",
       "      <td>AI1afa5f2c3c9b4b43def6dc2e695d2c87.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>AIace154420a51fad090b3543995630051.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>AI49658948b5f4eb06a3ddc2fa75eb41d0.jpg</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  image_path  label\n",
       "0       5eec66ec172ce096cd4e5c947686b56a.jpg      0\n",
       "1       ffc2e1fc7c886ec09a331040ada038aa.jpg      4\n",
       "2     AI6c3768639e82ceaeab681e083b897672.jpg      2\n",
       "3     AId98fac46793639eceaaa2e74cadd4973.jpg      6\n",
       "4       6e812fbc03331ab363789b0f2d6b3ff2.jpg      0\n",
       "...                                      ...    ...\n",
       "2095  AIa3dea07b2f7bf48276d32513091be717.jpg      5\n",
       "2096  AId47f1cb78db4a23e2516e2d34da34c8a.jpg      5\n",
       "2097  AI1afa5f2c3c9b4b43def6dc2e695d2c87.jpg      5\n",
       "2098  AIace154420a51fad090b3543995630051.jpg      4\n",
       "2099  AI49658948b5f4eb06a3ddc2fa75eb41d0.jpg      6\n",
       "\n",
       "[2100 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../Data/5.augmented_dataset.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-03 10:51:37.832432: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, auc, roc_auc_score, roc_curve\n",
    "from glob import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, GlobalAveragePooling1D, Flatten, Dense, Dropout \n",
    "from tensorflow.keras.layers import Rescaling, RandomFlip, RandomRotation, RandomZoom\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# os.environ[\"TF_KERAS\"]='1'\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134260544 (512.16 MB)\n",
      "Trainable params: 134260544 (512.16 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "base_model = VGG16()\n",
    "model = Model(inputs=base_model.inputs, outputs=base_model.layers[-2].output)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../Data/AugmentedImages/'\n",
    "\n",
    "def preprocess_image(image_file):\n",
    "    image = load_img(path+image_file, target_size=(224, 224))\n",
    "    image = img_to_array(image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    image = preprocess_input(image)\n",
    "    return image\n",
    "\n",
    "X = data.drop('label', axis=1).values\n",
    "y = data['label'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.2)\n",
    "\n",
    "image = preprocess_image(X_train)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test))\n",
    "\n",
    "\n",
    "images_features = []\n",
    "images_features.append(model.predict(image, verbose=0)[0]) # predict from pretrained model\n",
    "\n",
    "images_features = np.asarray(images_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Applications/anaconda3/envs/Projet6Env/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/Applications/anaconda3/envs/Projet6Env/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Applications/anaconda3/envs/Projet6Env/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Applications/anaconda3/envs/Projet6Env/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/Applications/anaconda3/envs/Projet6Env/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Applications/anaconda3/envs/Projet6Env/lib/python3.10/site-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model_6\" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(None, 1, 224, 224, 3)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 24\u001b[0m\n\u001b[1;32m     20\u001b[0m model \u001b[38;5;241m=\u001b[39m Model(inputs\u001b[38;5;241m=\u001b[39mbase_model\u001b[38;5;241m.\u001b[39minputs, outputs\u001b[38;5;241m=\u001b[39mbase_model\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39moutput)\n\u001b[1;32m     22\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 24\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Test Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/Projet6Env/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/kl/3nc79ycx61v13jbqlw61nnfw0000gn/T/__autograph_generated_file158nruck.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Applications/anaconda3/envs/Projet6Env/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/Applications/anaconda3/envs/Projet6Env/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Applications/anaconda3/envs/Projet6Env/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Applications/anaconda3/envs/Projet6Env/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/Applications/anaconda3/envs/Projet6Env/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Applications/anaconda3/envs/Projet6Env/lib/python3.10/site-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model_6\" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(None, 1, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "path = '../Data/AugmentedImages/'\n",
    "\n",
    "base_model = VGG16()\n",
    "model = Model(inputs=base_model.inputs, outputs=base_model.layers[-2].output)\n",
    "\n",
    "def preprocess_image(image_file):\n",
    "    image = load_img(path+image_file, target_size=(224, 224))\n",
    "    image = img_to_array(image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    image = preprocess_input(image)\n",
    "    return image\n",
    "\n",
    "X = np.array([preprocess_image(image_file) for image_file in data['image_path']])\n",
    "y = to_categorical(data['label'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "base_model = VGG16()\n",
    "model = Model(inputs=base_model.inputs, outputs=base_model.layers[-2].output)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "53/53 [==============================] - 302s 6s/step - loss: 11.2249 - accuracy: 0.7119 - val_loss: 2.0667 - val_accuracy: 0.7976\n",
      "Epoch 2/10\n",
      "53/53 [==============================] - 292s 6s/step - loss: 0.2670 - accuracy: 0.9506 - val_loss: 1.5312 - val_accuracy: 0.8452\n",
      "Epoch 3/10\n",
      "53/53 [==============================] - 294s 6s/step - loss: 0.0912 - accuracy: 0.9839 - val_loss: 1.3341 - val_accuracy: 0.8619\n",
      "Epoch 4/10\n",
      "53/53 [==============================] - 293s 6s/step - loss: 0.0127 - accuracy: 0.9970 - val_loss: 1.1919 - val_accuracy: 0.8690\n",
      "Epoch 5/10\n",
      "53/53 [==============================] - 292s 6s/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 1.2971 - val_accuracy: 0.8690\n",
      "Epoch 6/10\n",
      "53/53 [==============================] - 291s 6s/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 1.1930 - val_accuracy: 0.8810\n",
      "Epoch 7/10\n",
      "53/53 [==============================] - 291s 6s/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 1.1893 - val_accuracy: 0.8786\n",
      "Epoch 8/10\n",
      "53/53 [==============================] - 293s 6s/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 1.1895 - val_accuracy: 0.8738\n",
      "Epoch 9/10\n",
      "53/53 [==============================] - 293s 6s/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 1.1943 - val_accuracy: 0.8762\n",
      "Epoch 10/10\n",
      "53/53 [==============================] - 291s 6s/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 1.1938 - val_accuracy: 0.8762\n",
      "14/14 [==============================] - 58s 4s/step - loss: 1.1938 - accuracy: 0.8762\n",
      "Test Loss: 1.1938369274139404, Test Accuracy: 0.8761904835700989\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Charger le dataframe avec les noms de fichiers d'images et les labels\n",
    "# Supposons que le dataframe a deux colonnes : 'filename' et 'label'\n",
    "df = pd.read_csv('../Data/5.augmented_dataset.csv')\n",
    "path = '../Data/AugmentedImages/'\n",
    "\n",
    "# Prétraiter les images\n",
    "def preprocess_image(img_path):\n",
    "    img = image.load_img(path + img_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = preprocess_input(img_array)\n",
    "    return img_array\n",
    "\n",
    "# Charger les images et les labels\n",
    "X = np.vstack([preprocess_image(filename) for filename in df['image_path']])\n",
    "y = to_categorical(df['label'])\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Charger le modèle VGG16 sans la couche Dense supérieure (include_top=False)\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Gel des poids des couches VGG16 pré-entraînées\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Créer le modèle complet\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(7, activation='softmax'))  # Assurez-vous de définir correctement le nombre de classes\n",
    "\n",
    "# Compiler le modèle\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "checkpoint = ModelCheckpoint(\"best_model.h5\", monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)\n",
    "# Entraîner le modèle\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Évaluer le modèle\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss    : 1.1938369274139404\n",
      "Test accuracy: 0.8761904835700989\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print('Test loss    :', score[0])\n",
    "print('Test accuracy:', score[1])# mean absolute error ?????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Projet6Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
